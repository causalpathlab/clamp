s$importance_weight <- robust_importance_weights(R,
robust_method = robust_method,
robust_estimator = robust_estimator,
previous_importance_weight = s$importance_weight)
} else { ## robust_method != "none"
s$importance_weight <- rep(1, times = nrow(X))
}
if (!is.null(W)) {
W <- sweep(W, 1, s$importance_weight, "*")
} else {  ## is.null(W)
W <- s$importance_weight
}
# Fit WSER
res <- weighted_single_effect_regression(y=R, X=X,
W = W,
residual_variance = s$sigma2,
prior_inclusion_prob = s$pie,
prior_varB = s$prior_varB[l],
optimize_prior_varB = estimate_prior_method,
check_null_threshold = check_null_threshold)
res
res <- update_each_effect(X=X, y=y, s=s, W=W,
estimate_prior_method="none")
res
sum(logBF)
sum(res$logBF)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/initialize.R")
edit(susieR::susie_get_cs())
edit(susieR::susie_get_cs)
use_r("clamp_utils")
?inherits
source("~/Dropbox/paper-causal.susie/codes/clamp/R/clamp_utils.R")
View(susie_get_pip)
View(susie_init_coef)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/clamp.R")
set.seed(12345)
p <- 10
n <- 1000
X <- matrix(rnorm(n * p), nrow = n)
y <- 0.5*X[,1] + 0.8*X[,3] + 0.2*X[,7] + rnorm(n)
res <- clamp(X, y)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/model_linear.R")
set.seed(12345)
p <- 10
n <- 1000
X <- matrix(rnorm(n * p), nrow = n)
y <- 0.5*X[,1] + 0.8*X[,3] + 0.2*X[,7] + rnorm(n)
res <- clamp(X, y)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/elbo.R")
source("~/Dropbox/paper-causal.susie/codes/clamp/R/estimate_residual_variance.R")
set.seed(12345)
p <- 10
n <- 1000
X <- matrix(rnorm(n * p), nrow = n)
y <- 0.5*X[,1] + 0.8*X[,3] + 0.2*X[,7] + rnorm(n)
res <- clamp(X, y)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/clamp.R")
res <- clamp(X, y)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/clamp.R")
res <- clamp(X, y)
clamp <- function (X, y,
W = NULL, ## IPW matrix, should be of same size of X
maxL = min(10,ncol(X)),
family = c("linear", "binomial", "poisson"),
scaled_prior_variance = 0.2,
residual_variance = NULL,
prior_inclusion_prob = NULL,
null_weight = 0,
standardize = TRUE,
intercept = TRUE,
estimate_residual_variance = TRUE,
estimate_prior_variance = TRUE,
estimate_prior_method = c("optim", "EM", "simple"),
check_null_threshold = 0,
prior_tol = 1e-9,
residual_variance_upperbound = Inf,
robust_method = c("none", "huber"),
robust_estimator = c("M", "S"),
coverage = 0.95,
min_abs_corr = 0.5,
na.rm = FALSE,
max_iter = 500,
tol = 1e-3,
verbose = FALSE,
track_fit = FALSE,
residual_variance_lowerbound = var(drop(y))/1e4,
refine = FALSE,
n_purity = 100) {
# Process input estimate_prior_method.
estimate_prior_method = match.arg(estimate_prior_method)
# Process input robust_method
robust_method = match.arg(robust_method)
# Process input robust_estimator
robust_estimator = match.arg(robust_estimator)
# Check input X.
if (!(is.double(X) & is.matrix(X)) & !inherits(X,"CsparseMatrix") &
is.null(attr(X,"matrix.type")))
stop("Input X must be a double-precision matrix, or a sparse matrix, or ",
"a trend filtering matrix")
if (is.numeric(null_weight) && null_weight == 0)
null_weight = NULL
if (!is.null(null_weight) && is.null(attr(X,"matrix.type"))) {
if (!is.numeric(null_weight))
stop("Null weight must be numeric")
if (null_weight < 0 || null_weight >= 1)
stop("Null weight must be between 0 and 1")
if (missing(prior_inclusion_prob))
prior_inclusion_prob = c(rep(1/ncol(X) * (1 - null_weight),ncol(X)),
null_weight)
else
prior_inclusion_prob = c(prior_inclusion_prob * (1-null_weight),
null_weight)
X = cbind(X,0)
}
if (anyNA(X))
stop("Input X must not contain missing values")
if (anyNA(y)) {
if (na.rm) {
samples_kept = which(!is.na(y))
y = y[samples_kept]
X = X[samples_kept,]
} else
stop("Input y must not contain missing values")
}
p = ncol(X)
if (p > 1000 & !requireNamespace("Rfast",quietly = TRUE))
warning_message("For an X with many columns, please consider installing",
"the Rfast package for more efficient credible set (CS)",
"calculations.", style='hint')
# Process input family
family = match.arg(family)
model <- list()
model$type <- family
model$loglik <- Eloglik_linear
# switch(family,
#        "linear" =
#          {
#            model$loglik <- Eloglik_linear
#          },
#        "binomial" =
#          {
#            model$log_psd_var <-  ## logw2
#            model$psd_resp ## zz
#            model$loglik <-
#          },
#         "poisson" ={}
#        )
# Check input y.
n = nrow(X)
mean_y = mean(y)
# Check weight matrix W
if (!is.null(W) &
!(length(W) %in% c(nrow(X), nrow(X) * ncol(X))))
stop("The dim of Weights does not match with the dim of input X!")
# Center and scale input.
if (intercept)
y = y - mean_y
# Set three attributes for matrix X: attr(X,'scaled:center') is a
# p-vector of column means of X if center=TRUE, a p vector of zeros
# otherwise; 'attr(X,'scaled:scale') is a p-vector of column
# standard deviations of X if scale=TRUE, a p vector of ones
# otherwise; 'attr(X,'d') is a p-vector of column sums of
# X.standardized^2,' where X.standardized is the matrix X centered
# by attr(X,'scaled:center') and scaled by attr(X,'scaled:scale').
out = compute_colstats(X,center = intercept, scale = standardize)
attr(X,"scaled:center") = out$cm
attr(X,"scaled:scale") = out$csd
# attr(X,"d") = out$d
## standardize(?)
# Initialize susie fit.
s <- init_setup(n, p, maxL, family,
scaled_prior_variance,
residual_variance,
prior_inclusion_prob,
null_weight,
as.numeric(var(y)),
standardize)
s <- init_finalize(s)
# Initialize elbo to NA.
elbo = rep(as.numeric(NA),max_iter + 1)
elbo[1] = -Inf;
tracking = list()
# Initialize log-likelihood into NA
loglik = rep(as.numeric(NA),max_iter)  ## not required to know...
for (tt in 1:max_iter) {
if (track_fit)
tracking[[tt]] = clamp_slim(s)
s <- update_each_effect(X=X, y=y, s=s, W=W,
estimate_prior_variance = estimate_prior_variance,
estimate_prior_method = estimate_prior_method,
check_null_threshold = check_null_threshold,
robust_method = robust_method,
robust_estimator = robust_estimator)
if (verbose)
print(paste0("objective:", get_elbo(X, y, s, model)))
# Compute objective before updating residual variance because part
# of the objective s$kl has already been computed under the
# residual variance before the update.
elbo[tt+1] = get_elbo(X, y, s, model)
loglik[tt] = model$loglik(X, y, s)
if (verbose){
print(paste0("#iteration:", tt))
print(paste0("objective:", get_elbo(X, y, s, model)))
}
if (abs(elbo[tt+1] - elbo[tt]) < tol) {
# if ((elbo[tt+1] - elbo[tt]) < tol) {
s$converged = TRUE
break
}
if (estimate_residual_variance) {
s$sigma2 = pmax(residual_variance_lowerbound,
estimate_residual_variance_fun(X,y,s))
if (s$sigma2 > residual_variance_upperbound)
s$sigma2 = residual_variance_upperbound
}
}
# Remove first (infinite) entry, and trailing NAs.
elbo = elbo[2:(tt+1)]
s$elbo = elbo
s$niter = tt
loglik = loglik[1:tt]
s$loglik = loglik
if (is.null(s$converged)) {
warning(paste("IBSS algorithm did not converge in",max_iter,"iterations!"))
s$converged = FALSE
}
if (intercept) {  ################### How about the glm cases?
# Estimate unshrunk intercept.
s$intercept = mean_y - sum(attr(X,"scaled:center") *
(colSums(s$alpha * s$mu)/attr(X,"scaled:scale")))
s$fitted = s$Xr + mean_y
} else {
s$intercept = 0
s$fitted = s$Xr
}
s$fitted = drop(s$fitted)
names(s$fitted) = `if`(is.null(names(y)),rownames(X),names(y))
if (track_fit)
s$trace = tracking
# SuSiE CS and PIP.
if (!is.null(coverage) && !is.null(min_abs_corr)) {
s$sets = clamp_get_cs(s,coverage = coverage,X = X,
min_abs_corr = min_abs_corr,
n_purity = n_purity)
s$pip = clamp_get_pip(s,prune_by_cs = FALSE,prior_tol = prior_tol)
}
if (!is.null(colnames(X))) {
variable_names = colnames(X)
if (!is.null(null_weight)) {
variable_names[length(variable_names)] = "null"
names(s$pip) = variable_names[-p]
} else
names(s$pip)    = variable_names
colnames(s$alpha) = variable_names
colnames(s$mu)    = variable_names
colnames(s$mu2)   = variable_names
colnames(s$betahat) = variable_names
colnames(s$logBF_variable) = variable_names
}
# For prediction.
s$X_column_scale_factors = attr(X,"scaled:scale")
return(s)
}
source("~/Dropbox/paper-causal.susie/codes/clamp/R/clamp.R")
res <- clamp(X, y)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/clamp_utils.R")
res <- clamp(X, y)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/initialize.R")
res <- clamp(X, y)
res
summary.clamp(res)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/summary.clamp.R")
summary.clamp(res)
res_susie <- susieR::susie(X, y)
summary(res_susie)
summary(res)
res$pip
res_su$pip
res_susie$pip
res$elbo
res_susie$elbo
clamp_get_pip(su)
clamp_get_pip(res)
clamp_get_posterior_mean(res)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/clamp_utils.R")
clamp_get_posterior_mean(res_susie)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/clamp.R")
res <- clamp(X, y)
clamp_get_posterior_mean(res)
use_test("weighted_single_effect_regression")
rm(list = ls())
aa <- matrix(1:9, nrow = 3)
aa
bb <- c(1, 2, 3)
sweep(aa, 1, bb, "-")
?solve
?diag
source("~/Dropbox/paper-causal.susie/codes/clamp/R/weighted_single_effect_regression.R")
use_test("weighted_single_effect_regression")
set.seed(12345)
p <- 10
n <- 1000
X <- matrix(rnorm(n * p), nrow = n)
y <- 0.5*X[,1] + 0.8*X[,3] + 0.2*X[,7] + rnorm(n)
out = compute_colstats(X,center = T, scale = T)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/compute_colstats.R")
out = compute_colstats(X,center = T, scale = T)
attr(X,"scaled:center") = out$cm
attr(X,"scaled:scale") = out$csd
res <- weighted_single_effect_regression(y=y, X=X, prior_varB=1)
res
out
W=NULL
prior_varB <- 1
residual_variance <- 1
prior_inclusion_prob = NULL
optimize_prior_varB <- "none"
check_null_threshold = 0
p <- ncol(X)
# Check W
if (is.null(W)) {
W <- rep(1, times = nrow(X))
} else if (length(W) == nrow(X)) {  ## (n by 1) vector
W <- as.numeric(W)
} else if (length(W) == nrow(X)*ncol(X)) {  ## (n by p) matrix
if (dim(W)[1] != nrow(X))
stop("Dimensions of the W do not match!")
} else {
stop("Dimensions of the W do not match!")
}
dim(W)
# Check W
if (is.null(W)) {
W <- rep(1, times = nrow(X))
} else if (length(W) == nrow(X)) {  ## (n by 1) vector
W <- as.numeric(W)
} else if (length(W) == nrow(X)*ncol(X)) {  ## (n by p) matrix
if (dim(W)[1] != nrow(X))
stop("Dimensions of the W do not match!")
} else {
stop("Dimensions of the W do not match!")
}
dim(W)
W[1:3]
# Scale X
X_ <- sweep(X, 2, attr(X, "scaled:center"), "-")  ## centralized
X_ <- sweep(X_, 2, attr(X, "scaled:scale"), "/")
# Update the MLE (using scaled X)
if (length(W) == nrow(X)) {  ## weight is an (n by 1) vector
XtWX <- colSums(sweep(X_ * X_, 1, W, "*"))
XtWY <- colSums(sweep(X_, 1, W * y, "*"))
} else {  ## weight is an (n by p) matrix
XtWX <- colSums(X_ * X_ * W)
XtWY <- colSums(sweep(X_ * W, 1, y, "*"))
}
XtWY
XtWX
betahat <- XtWY / XtWX  # = shat2 * XtWY
betahat
XtWX
XtWY
(1 / XtWX) * XtWY
out
betahat
shat2
shat2 <- residual_variance / XtWX
shat2
# Check prior_inclusion_probability
## If `prior_inclusion_probability` is consistent to all variables,
## its value should not affect the posterior inclusion probability (alpha).
if (is.null(prior_inclusion_prob)) {
prior_inclusion_prob <- rep(1/p, times = p)  ## other value?
} else {
if (length(prior_inclusion_prob) != p)
stop("The length of prior inclusion probability does not match")
}
if (optimize_prior_varB != "EM" && optimize_prior_varB != "none") {
prior_varB <- optimize_prior_variance(optimize_prior_varB, betahat, shat2,
prior_inclusion_prob,
alpha = NULL, post_mean2 = NULL,
prior_varB_init = prior_varB,
check_null_threshold = check_null_threshold)
}
prior_varB
# compute log of Bayes factor (logBF) and log of posterior odds (logPO)
zscore2 <- betahat^2 / shat2
logBF <- 1/2 * ((log(shat2) - log(shat2 + prior_varB)) +
zscore2 * prior_varB / (prior_varB + shat2))
logPO <- logBF + log(prior_inclusion_prob + sqrt(.Machine$double.eps))
logPO
# deal with special case of infinite shat2
# (e.g. happens if X does not vary)
logBF[is.infinite(shat2)] <- 0
logPO[is.infinite(shat2)] <- 0
maxlogPO <- max(logPO)
# logPO_tilde is proportional to posterior odds = BF * prior,
# but subtract max for numerical stability
logPO_weighted <- exp(logPO - maxlogPO)
logPO_weighted
# Update the posterior estimates
# Posterior prob for each variable
alpha <- logPO_weighted / sum(logPO_weighted)    # posterior inclusion probability
post_var <- 1 / (1/shat2 + 1/prior_varB)                      # posterior variance
post_mean <- prior_varB / (prior_varB + shat2) * XtWY / XtWX  # posterior mean
post_mean2 <- post_var + post_mean^2                          # posterior second moment
alpha
logBF <- 1/2 * (log(shat2 /(shat2 + prior_varB)) +
zscore2 * prior_varB / (prior_varB + shat2))
logPO <- logBF + log(prior_inclusion_prob + sqrt(.Machine$double.eps))
logBF
# Update the posterior estimates
# Posterior prob for each variable
alpha <- logPO_weighted / sum(logPO_weighted)    # posterior inclusion probability
post_var <- 1 / (1/shat2 + 1/prior_varB)                      # posterior variance
post_mean <- prior_varB / (prior_varB + shat2) * XtWY / XtWX  # posterior mean
post_mean2 <- post_var + post_mean^2                          # posterior second moment
# ABF for WSER model
logBF_model <- maxlogPO + log(sum(logPO_weighted))
logBF_model
post_mean
rm(X, y, n, p, out, res)
rm(maxlogPO)
set.seed(12345)
p <- 10
n <- 1000
X <- matrix(rnorm(n * p), nrow = n)
y <- 0.5*X[,1] + 0.8*X[,3] + 0.2*X[,7] + rnorm(n)
out = compute_colstats(X,center = T, scale = T)
attr(X,"scaled:center") = out$cm
attr(X,"scaled:scale") = out$csd
res <- weighted_single_effect_regression(y=y, X=X, prior_varB=1)
res
W <- matrix(1, nrow = n, ncol = p)
# res <- weighted_single_effect_regression(y=y, X=X, prior_varB=1)
res <- weighted_single_effect_regression(y=y, X=X, W=W, prior_varB=1)
res
.loge <- function(t) log(t+.Machine$double.eps)
set.seed(1234567)
p <- 10
n <- 1000
X <- matrix(rnorm(n * p), nrow = n)
y <- 0.5*X[,1] + 0.8*X[,3] + 0.2*X[,7] + rnorm(n)
W <- matrix(1, nrow = n, ncol = p)
out = compute_colstats(X,center = T, scale = T)
attr(X,"scaled:center") = out$cm
attr(X,"scaled:scale") = out$csd
res <- weighted_single_effect_regression(y=y, X=X, W=W, prior_varB=1,
optimize_prior_varB = "optim")
res
res <- weighted_single_effect_regression(y=y, X=X, W=W, prior_varB=1,
optimize_prior_varB = "EM")
res
use_test("weighted_single_effect_regression")
source("~/Dropbox/paper-causal.susie/codes/clamp/R/robust_importance_weights.R")
use_test("update_each_effect")
source("~/Dropbox/paper-causal.susie/codes/clamp/R/update_each_effect.R")
rm(aa, out, res, W, X, X_, alpha, bb, betahat, check_null_threshold, logBF, logBF_model, logPO, logPO_weighted)
rm(n, optimize_prior_varB, p, post_mean, post_mean2, post_var)
rm(prior_inclusion_prob, prior_varB, residual_variance, shat2, y, XtWX, XtWY)
rm(zscore2)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/model_linear.R")
source("~/Dropbox/paper-causal.susie/codes/clamp/R/estimate_residual_variance.R")
source("~/Dropbox/paper-causal.susie/codes/clamp/R/elbo.R")
source("~/Dropbox/paper-causal.susie/codes/clamp/R/compute_colstats.R")
set.seed(12345)
p <- 10
n <- 1000
X <- matrix(rnorm(n * p), nrow = n)
y <- 0.5*X[,1] + 0.8*X[,3] + 0.2*X[,7] + rnorm(n)
out = compute_colstats(X,center = T, scale = T)
attr(X,"scaled:center") = out$cm
attr(X,"scaled:scale") = out$csd
attr(X, "d") = out$d
family <- "linear"
s <- init_setup(n, p, maxL, family,
scaled_prior_variance,
residual_variance,
prior_inclusion_prob,
null_weight,
as.numeric(var(y)),
standardize)
source("~/Dropbox/paper-causal.susie/codes/clamp/R/initialize.R")
s <- init_setup(n, p, maxL, family,
scaled_prior_variance,
residual_variance,
prior_inclusion_prob,
null_weight,
as.numeric(var(y)),
standardize)
s <- init_setup(n, p, maxL=10,
family="linear",
scaled_prior_variance=0.2,
residual_variance=1,
prior_inclusion_prob=NULL,
null_weight=0,
varY=as.numeric(var(y)),
standardize=TRUE)
s <- init_finalize(s)
if (TRUE)
y_ = y -  mean(y)
# weight matrix W
W <- matrix(1, nrow = n, ncol = p)
res <- update_each_effect(X=X, y=y_, s=s, W=W,
estimate_prior_method="none")
source("~/Dropbox/paper-causal.susie/codes/clamp/R/sparse_multiplication.R")
res <- update_each_effect(X=X, y=y_, s=s, W=W,
estimate_prior_method="none")
res
source("~/Dropbox/paper-causal.susie/codes/clamp/R/update_each_effect.R")
res <- update_each_effect(X=X, y=y_, s=s, W=W,
estimate_prior_method="none")
res
